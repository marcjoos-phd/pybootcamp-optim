{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code optimization and good practices: make the best of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Python bootcamp@SAp*, Marc Joos (LMPA) \n",
    "\n",
    "This Notebook is under a [**CreativeCommons BY-NC-SA v.4.0**](https://creativecommons.org/licenses/by-nc-sa/4.0/) license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble: optimize what needs to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Premature optimization is the root of all evil.*\n",
    ">\n",
    ">                            â€” Donald Knuth\n",
    "\n",
    "A good developement pattern is something like:\n",
    " 1. get your program right\n",
    " 2. test it right\n",
    " 3. profile it if you're not satisfy with the performance\n",
    " 4. optimize\n",
    " 5. repeat from 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The IPython `%timeit` magic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%timeit` is very convenient to profile pieces of code in the interactive IPython shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loop(nx=100, ny=100):\n",
    "    for i in xrange(nx):\n",
    "        for j in xrange(ny):\n",
    "            res = i**2 + i*j\n",
    "    return res\n",
    "\n",
    "%timeit loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cProfile** is the Python profiling interface. It can be use to profile a whole code, and can be called just through your shell command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('loop()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, in your favorite shell:\n",
    "\n",
    "`~$ python -m cProfile myscript.py`\n",
    "\n",
    "You should be careful though, **cProfile** is designed to give the profile of a given program, but shouldn't be used for benchmarking purpose. The profiler introduces overhead in the Python code that are not in your C/Fortran/whitespace functions; they will inevitably look faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code I: Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is slow because it is an interpreted language; everything as to be evaluated on the fly, with little or no possibility of optimization by the interpreter. C, Fortran and other compiled languages are more efficient because the processor can optimize lots of things at compile time. But most of the time, if you use Python you probably don't want to swith to a compiled language, with a steeper learning curve, little or no plotting possibilities, and a longer development cycle.\n",
    "\n",
    "**Cython** is a good starting point to optimize your code, without modifying it too much or relying too strongly on bits of code written in another language. The idea is very simple: take you Python code, define some variables in a C-like way, and compile it as a C module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a simple function to compute $\\pi$, by integrating $f(x) = \\frac{4}{1 + x^2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = lambda x: 4./(1. + x*x)\n",
    "\n",
    "def compPi(niter=1000):\n",
    "    h  = 1./niter\n",
    "    pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we time it, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipyversion = %timeit -o compPi()\n",
    "times = []; labels = []\n",
    "times.append(pipyversion.best)\n",
    "labels.append('Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to copy/paste your code in a `.pyx` file, that you will then compile.\n",
    "\n",
    "(For the sake of simplicity for the workshop, I'll use the magic `cython` function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "f = lambda x: 4./(1. + x*x)\n",
    "\n",
    "def compPi_cython(niter=1000):\n",
    "    h  = 1./niter\n",
    "    pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picy1version = %timeit -o compPi_cython()\n",
    "times.append(picy1version.best)\n",
    "labels.append('Cython (copypasta)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is pretty cool: doing nothing but a copypasta, we already improved the performance! But we can do better; first, by declaring some variables, second, by redefining our `f` function in a C way (using `cdef` instead of `def`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "cdef double f(double x):\n",
    "    return 4./(1. + x*x)\n",
    "\n",
    "def compPi_cython(int niter=1000):\n",
    "    cdef:\n",
    "        int i\n",
    "        double error\n",
    "        double h  = 1./niter\n",
    "        double pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picy2version = %timeit -o compPi_cython()\n",
    "times.append(picy2version.best)\n",
    "labels.append('Cython (with cdef)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Since `f` was defined using `cdef`, it can be called only in the Cython module. The advantage is that it is closer to a \"real\" C function, and it removes some overheads of the Python functions. If you need the function to be called both from Cython and Python, you can use `cpdef`; it will then produce (at compile time) two versions of the function: one for Cython, and one for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cython comes with directives (that you can use as decorator) to further optimize your code. In particular, there is (find all the directives on the [Cython compilation page](http://docs.cython.org/src/reference/compilation.html)):\n",
    "- `boundcheck`: if `False`, Cython presumes the indices existence (default: `True`);\n",
    "- `wraparound`: if `False`, Cython does not check if the index is negative (default: `True`);\n",
    "- `cdivision`: if `True`, Cython uses C division (default: `False`).\n",
    "\n",
    "Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cdef double f(double x):\n",
    "    return 4./(1. + x*x)\n",
    "\n",
    "def compPi_cython(int niter=1000):\n",
    "    cdef:\n",
    "        int i\n",
    "        double error\n",
    "        double h  = 1./niter\n",
    "        double pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picy3version = %timeit -o compPi_cython()\n",
    "times.append(picy3version.best)\n",
    "labels.append('Cython (with decorators)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these results to summarize what we have achieve so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "def plotElpTime(times, labels, *args, **kwargs):\n",
    "    fig = pl.figure(figsize=(len(times)*2,5))\n",
    "    pl.title(r'Elapsed time for $\\pi$ computation')\n",
    "    pl.ylabel('time (s)')\n",
    "    pl.xticks(range(len(times)), labels)\n",
    "    pl.xlim(-0.5, len(times)-0.5)\n",
    "    pl.semilogy(times, 'ro')\n",
    "    return fig\n",
    " \n",
    "fig = plotElpTime(times, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling other Cython modules in Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Cython script can be split in two parts, one with the declarations (a `.pxd` file) and one with the rest of the code (a `.pyx` file). Then, if you need something declared in another Cython module's definition file, you can `import` (for Python-like functions) or `cimport` (for C like functions) the module in your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "``` python\n",
    "# First Cython module (mod1.pyx)\n",
    "\n",
    "cdef myFunc(type arg):\n",
    "    doSomething\n",
    "    return things\n",
    "\n",
    "def myPyFunc(type arg):\n",
    "    doSomething\n",
    "    return things\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "``` python\n",
    "# Definition file (mod1.pxd)\n",
    "\n",
    "cdef myFunc(type arg)\n",
    "def myPyFunc(type arg)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "``` python\n",
    "# Second Cython module (another pyx file)\n",
    "cimport mod1 as cmod1\n",
    "import mod1 as pmod1\n",
    "\n",
    "cdef anotherFunc(type arg):\n",
    "    something = pmod1.myPyFunc(arg)\n",
    "    somethingElse = cmod1.myFunc(arg)\n",
    "    return otherThings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, NumPy can be interfaced with Cython using this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python version:\n",
    "import numpy as np\n",
    "\n",
    "def dummyLoop(nx=100, ny=100):\n",
    "    arr = np.zeros((nx,ny))\n",
    "    for i in xrange(nx):\n",
    "        for j in xrange(ny):\n",
    "            arr[i,j] = i*i + i*j\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dummyLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "# Cython version:\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "\n",
    "def dummyLoop_cython(int nx=100, int ny=100):\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=2] arr = np.zeros((nx,ny))\n",
    "    for i in xrange(nx):\n",
    "        for j in xrange(ny):\n",
    "            arr[i,j] = i*i + i*j\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dummyLoop_cython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping C/C++ functions with Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cython allows you also to wrap C/C++ functions, with the same mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Header file\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double sin(double angle)\n",
    "    double cos(double angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life, you'll need to compile your Cython scripts. To do so, you have to put your Cython program in a `.pyx` file, and then you just have to create a Makefile that looks like this:\n",
    "\n",
    "```bash\n",
    "    FCC = gcc\n",
    "    PYINC = $CONDAPATH/include/python2.7 # with $CONDAPATH the path of your current Anaconda installation\n",
    "\n",
    "    all:\n",
    "        cython cutils.pyx\n",
    "        $(FCC) -fPIC -shared -O3 -Wall -fno-strict-aliasing -I$(PYINC) -o cutils.so cutils.c\n",
    "```\n",
    "\n",
    "Then, all you have to do is to compile the script with `make`, and call it in your Python scripts with\n",
    "\n",
    "```python\n",
    "    import cutils\n",
    "```\n",
    "\n",
    "**Note for Windows users:** you would need to generate a `.pyd` file instead of a `.so` file. You can use MinGW compiler that contains `gcc` to compile your code.\n",
    "\n",
    "More informations for Windows:\n",
    " - [compilation on Cython website](http://docs.cython.org/src/reference/compilation.html)\n",
    " - [MinGW on Cython website](http://docs.cython.org/src/tutorial/appendix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code II: `ctypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative to directly wrap your C code in Python is **`ctypes`**. `ctypes` is from the standard library, and actually allows you to call any C compiled library into Python. It is slightly less user-friendly than Cython, and it is very architecture-specific: the library extensions are not the same on different plateforms (Windows `dll` vs. \\*NIX `so`), and you can have 32/64bit problems.\n",
    "\n",
    "That being said, you can proceed first by creating your C source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file mylib.c\n",
    "#include <math.h>\n",
    "\n",
    "double f(double x) {\n",
    "        return 4./(1. + x*x); \n",
    "}\n",
    "\n",
    "double compPi_ctypes(double pi, int niter) {\n",
    "    double h = 1./niter;\n",
    "    double x = 0.;\n",
    "    for (int i=0; i<niter; ++i){\n",
    "        x = h*(i - 0.5);\n",
    "        pi += f(x);\n",
    "    }\n",
    "    pi *= h;\n",
    "    return pi;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc -std=c99 -c -fPIC mylib.c\n",
    "gcc -shared -o mylib.so mylib.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "# import the C library\n",
    "mylib = ctypes.CDLL('mylib.so')\n",
    "# declare result type: default is int\n",
    "mylib.compPi_ctypes.restype = ctypes.c_double\n",
    "# declare arguments type\n",
    "pi = ctypes.c_double(0.); niter = ctypes.c_int(1000)\n",
    "\n",
    "pictversion = %timeit -o mylib.compPi_ctypes(pi, niter)\n",
    "times.append(pictversion.best)\n",
    "labels.append('Ctypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plotElpTime(times, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code III: f2py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f2py` is to Fortran what `ctypes` is to C: you can wrap directly your fortran routines in a Python module. it comes from NumPy, and you'll obviously need a Fortran compiler on your machine to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file futils.f90\n",
    "module futils\n",
    "contains\n",
    "    function f(x) result(res)\n",
    "        implicit none\n",
    "        real(8), intent(in) :: x\n",
    "        real(8) :: res\n",
    "                \n",
    "        res = 4.d0/(1.d0 + x*x)\n",
    "    end function f\n",
    "    \n",
    "\n",
    "    subroutine compPi_fortran(pi, error, niter)\n",
    "        implicit none\n",
    "        \n",
    "        integer, intent(in) :: niter\n",
    "        real(8), intent(out) :: pi, error\n",
    "        real(8) :: h, x\n",
    "        integer :: i        \n",
    "\n",
    "        h = 1.d0/niter\n",
    "        pi = 0.d0\n",
    "        error = 0.d0\n",
    "        \n",
    "        do i = 1, niter\n",
    "            x = h*(i - 0.5d0)\n",
    "            pi = pi + f(x)\n",
    "        enddo\n",
    "        pi = pi*h\n",
    "        \n",
    "        error = abs(acos(-1.d0) - pi)/acos(-1.d0)\n",
    "    end subroutine compPi_fortran\n",
    "\n",
    "end module futils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compile it with `f2py`; the `-m futils` option sets the name of the Python module it will produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!f2py -c -m futils futils.f90 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this can be simply called from Python, as any Python module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from futils import futils\n",
    "\n",
    "pifpyversion = %timeit -o futils.comppi_fortran(1000)\n",
    "times.append(pifpyversion.best)\n",
    "labels.append('F2Py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plotElpTime(times, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass NumPy arrays transparently between Python and your Fortran module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file futils_arr.f90\n",
    "module futils_arr\n",
    "contains\n",
    "    subroutine loop_fortran(arr, nx, ny)\n",
    "        implicit none\n",
    "        integer, intent(in) :: nx, ny\n",
    "        integer, dimension(nx,ny), intent(inout) :: arr\n",
    "        integer :: i, j\n",
    "                \n",
    "        do j = 1, ny\n",
    "            do i = 1, nx\n",
    "                arr(i,j) = i*i + i*j\n",
    "            enddo\n",
    "        enddo\n",
    "        \n",
    "    end subroutine loop_fortran\n",
    "end module futils_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!f2py -c -m futils futils.f90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from futils_arr import futils_arr\n",
    "\n",
    "nx = 100; ny = 100\n",
    "arr = np.zeros((nx,ny), dtype='i4', order='F')\n",
    "%timeit futils_arr.loop_fortran(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I had to define the order of the numpy array; by default, arrays are C-ordered (meaning in row-major order), whereas Fortran arrays are column-major ordered. The order of a NumPy array can be set with the `order` option, with `C` for C-order and `F` for Fortran-order.\n",
    "\n",
    "If you want to pass an existing array to Fortran, you can copy it and just change its order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check array order\n",
    "def arrayOrder(arr):\n",
    "    try:\n",
    "        assert(type(arr) == np.ndarray)\n",
    "    except AssertionError:\n",
    "        'This is not an array'\n",
    "        sys.exit(0)\n",
    "    orderF = arr.flags.f_contiguous\n",
    "    orderC = arr.flags.c_contiguous\n",
    "    if orderF and orderC:\n",
    "        return 'array is in C and Fortran order'\n",
    "    elif orderF:\n",
    "        return 'array is in Fortran order'\n",
    "    else:\n",
    "        return 'array is in C order'\n",
    "\n",
    "arr = np.zeros((nx,ny))\n",
    "print ('arr: ' + arrayOrder(arr))\n",
    "arrF = arr.copy(order='F')\n",
    "print ('arrF: ' + arrayOrder(arrF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f2py with interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed that we had to define the array returned by `f2py` before calling the function, which seems a bit awkward. In this particular case, would seem more logical to pass the dimensions of the desired array, and to get as a result an array.\n",
    "\n",
    "It can actually be done using an *interface file*, that is kind of a header file for `f2py`, with a `pyf` extension. This file can be automatically generated by `f2py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!f2py --overwrite-signature futils.f90 -m futils -h futils.pyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!more futils.pyf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore simply rewrite this file, redefining the array as an `intent(out)` variable, with a dependency on the array dimensions. The dimensions just need to be `intent(in)` variables, with no dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file futils.pyf\n",
    "!    -*- f90 -*-\n",
    "! Note: the context of this file is case sensitive.\n",
    "\n",
    "python module futils ! in \n",
    "    interface  ! in :futils\n",
    "        module futils ! in :futils:futils.f90\n",
    "            subroutine loop_fortran(arr,nx,ny) ! in :futils:futils.f90:futils\n",
    "                integer, dimension(nx,ny), intent(out), depend(nx,ny) :: arr\n",
    "                integer, intent(in) :: nx\n",
    "                integer, intent(in) :: ny\n",
    "            end subroutine loop_fortran\n",
    "        end module futils\n",
    "    end interface \n",
    "end python module futils\n",
    "\n",
    "! This file was auto-generated with f2py (version:2).\n",
    "! See http://cens.ioc.ee/projects/f2py2e/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recompile and call it from Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!f2py -c -m futils futils.pyf futils.f90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from futils import futils\n",
    "%timeit futils.loop_fortran(100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for Windows users:** `f2py` can be used under Windows, either with Cygwin or with MinGW (as for Cython). More details on the [F2Py Q&A webpage](https://sysbio.ioc.ee/projects/f2py2e/FAQ.html#q-how-to-use-f2py-under-windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code IV: Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of using Python is to avoid all the compilation steps and all the associated inconveniences. Clearly, with all the previous examples, the compilation step seems once again unavoidable if you want to keep up with good performances.\n",
    "\n",
    "However, with tools as **Numba**, this can be avoided. Numba is a *Just-In-Time compiler* relying on LLVM; it means that machine code can be generated dynamically, on the fly, during the execution.\n",
    "\n",
    "**Numba** can be use simply with the `autojit` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import autojit\n",
    "\n",
    "# The Python functions to compute pi:\n",
    "f = lambda x: 4./(1. + x*x)\n",
    "\n",
    "def compPi(niter=1000):\n",
    "    h  = 1./niter\n",
    "    pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f_numba(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error\n",
    "\n",
    "# The Just-In-Time-compiled version:\n",
    "@autojit\n",
    "def f_numba(x):\n",
    "    return 4./(1. + x*x)\n",
    "\n",
    "@autojit\n",
    "def compPi_numba(niter=1000):\n",
    "    h  = 1./niter\n",
    "    pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f_numba(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit compPi(1000)\n",
    "pinumbaversion = %timeit -o compPi_numba(1000)\n",
    "times.append(pinumbaversion.best)\n",
    "labels.append('Numba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plotElpTime(times, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And therefore, with almost no effort or modifications of the code, we get a results only a few percents slower than the best we had with compiled code.\n",
    "\n",
    "Bad news is Numba is still young and still struggle to take the best of Python, in particular with complex code -- it can be slower than pure Python+NumPy. It does not support (yet?) list comprehension either. But it is always worth trying, to see what you can achieve with this simple approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code V: other alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other existing alternatives to Cython, ctypes, f2py or numba I presented here. In particular, there is:\n",
    "- [Python C API](http://docs.python.org/2/c-api/): Python is implemented in C, and you can actually write C code which will compile to a Python module! This is extremely low-level, and I would only recommend it if you enjoy pain (see Dan Foreman-Mackie's [blog post](http://dan.iel.fm/posts/python-c-extensions/) for a concise-as-possible introduction);\n",
    "- [SWIG](http://www.swig.org/): the Simplified Wrapper Interface Generator, can generate wrappers from a variety of low-level languages to a variety of high-level languages.  It's used heavily by LSST and other projects;\n",
    "- [Weave](http://docs.scipy.org/doc/scipy/reference/tutorial/weave.html): included in SciPy, weave is a method of putting C snippets within a Python program.  It's largely been superseded by Cython in practice;\n",
    "- [PyPy](http://pypy.org/): a JIT compiler for Python written in Python.  PyPy doesn't support the C backend which most scientific tools rely on, so it's not extremely useful for scientific computing. Typically, forget it if you use NumPy (and I guess I just lost everybody in the room)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up your code VI: Concurrent and parallel computing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python allows, to a certain point, to use **parallel** or **concurrent** computing, using multiple threads or processes.The simplest, to use concurrency, is to use the `multiprocessing` package. `multiprocessing` is using processes and not threads because of the Python interpreter that is not thread-safe: some internal data structures are accessible by one thread and one thread only at a time, and everything is under control by the GIL (Global Interpreter Lock). To circumvent this problem, multprocessing is using different processes on which the critical data structures are independently copied.\n",
    "\n",
    "**Note for Windows users:** there are some differences in the code you should write on Windows, because Windows lacks `os.fork()` (it basically does not manage processes the same way as in \\*NIX). More infos on the [multiprocessing webpage](https://docs.python.org/2/library/multiprocessing.html#windows).\n",
    "\n",
    "In the first example, we create a process for every call (here of a function, that will perform a given task) we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "def doSomething(wdir='./'):\n",
    "    print('working on process: %d' %os.getpid())\n",
    "    print(os.listdir(wdir))\n",
    "    \n",
    "def launchSimple(listdir=('./', '../',)):\n",
    "    for wdir in listdir:\n",
    "        # Create processes\n",
    "        p = mp.Process(target=doSomething, args=(wdir,))\n",
    "        # Launch processes\n",
    "        p.start()\n",
    "        # Wait until processes terminate\n",
    "        p.join()\n",
    "        \n",
    "launchSimple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the limitation of this first example: we can execute in parallel independent tasks, but we cannot get back the results. The simplest is to use a queue, in which we will put the results of every process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doItInQueue(q, wdir='./'):\n",
    "    print('working on process: %d' %os.getpid())\n",
    "    q.put(os.listdir(wdir))\n",
    "    \n",
    "def launchQueue(listdir=('./', '../',)):\n",
    "    # Create queue\n",
    "    q = mp.Queue()\n",
    "    result = []\n",
    "    for wdir in listdir:\n",
    "        # Create processes\n",
    "        p = mp.Process(target=doItInQueue, args=(q, wdir))\n",
    "        # Launch processes\n",
    "        p.start()\n",
    "        # Wait until processes terminate\n",
    "        p.join()\n",
    "        # Get results\n",
    "        result.append(q.get())\n",
    "    return result\n",
    "\n",
    "launchQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, reading the multiprocessing documentation, you realize that you could it in an even simpler way, using pools of processes with `Pool()`. Pools come with a map method, that works as the classical map function in Python (you can map a function on a list of arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doItInPool(wdir='./'):\n",
    "    print('working on process: %d' %os.getpid())\n",
    "    return os.listdir(wdir)\n",
    "\n",
    "def launchPool(listdir=['./', '../']):\n",
    "    # Get number of CPU available and define the number of processes\n",
    "    nproc  = mp.cpu_count()*2\n",
    "    # Create pool\n",
    "    pool   = mp.Pool(processes=nproc)\n",
    "    # Distribute the work among processes\n",
    "    result = pool.map(doItInPool, listdir)\n",
    "    return result\n",
    "\n",
    "launchPool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for a more advance use, you can create queues to manage both the tasks to execute and the results to get back, with workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doItWithWorker(tasks, results):\n",
    "    for i, task in iter(tasks.get, 'STOP'):\n",
    "        results.put((i, os.getpid(), os.listdir(task)))\n",
    "    \n",
    "def launchWorker(listdir=['./', '../']):\n",
    "    # Get number of CPU available and define the number of processes\n",
    "    nproc   = mp.cpu_count()*2\n",
    "    # Create queues\n",
    "    tasks   = mp.Queue()\n",
    "    results = mp.Queue()\n",
    "\n",
    "    # Create list of tasks\n",
    "    for i, out in enumerate(listdir):\n",
    "        tasks.put((i, out))\n",
    "\n",
    "    # Distribute the work among processes\n",
    "    for i in xrange(nproc-1):\n",
    "        p = mp.Process(target=doItWithWorker, args=(tasks, results))\n",
    "        p.start()\n",
    "\n",
    "    # Tell processes to stop when they are done\n",
    "    for i in xrange(nproc-1):\n",
    "        tasks.put('STOP')\n",
    "    \n",
    "    # Gather results\n",
    "    result = []\n",
    "    for i in xrange(len(listdir)):\n",
    "        j, pid, res = results.get()\n",
    "        print('Task #%02d was done on process #%d' %(j,pid))\n",
    "        result.append(res)\n",
    "\n",
    "    return result\n",
    "\n",
    "launchWorker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very last alternative is to use `mpi4py`. For one used to parallel programming, it is utterly simple to use: you just have to create a global communicator, and then to do your domain decomposition. In the end, you could retrieve the data through a communication (typically a `comm.Gather()` call in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file parallel.py\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import argparse\n",
    "from mpi4py import MPI\n",
    "\n",
    "def launchMPI(listdir=['./', '../']):\n",
    "    # Initialize MPI creating COMM_WORLD communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    # Get size of the MPI domain and rank of the process\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank()\n",
    "    \n",
    "    # Distribute work among MPI processes\n",
    "    nfp = len(listdir)/size\n",
    "    for i in xrange(nfp+1):\n",
    "        idx = i*size + rank\n",
    "        print('working on process: %d with PID: %d' %(rank,os.getpid()))\n",
    "        if idx < len(listdir):\n",
    "            print(os.listdir(listdir[idx]))\n",
    "        else:\n",
    "            print('Nothing to be done.')\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser.add_argument('--with-mpi', '-m', dest='mpi', action='store_true' \\\n",
    "                            , help='to launch MPI test')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    mpi = args.mpi\n",
    "    if mpi: launchMPI()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod +x parallel.py\n",
    "mpirun -np 4 ./parallel.py -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `range` vs. `xrange` -- always prefer iterators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `range(n)` generates a list of `n` elements, that is stored in memory\n",
    " - `xrange(n)` generates an iterator; integers are generated when requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print sys.getsizeof(range(1000))\n",
    "print sys.getsizeof(xrange(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there are lots of already-made iterators waiting for you out there. Typically, dictonaries also come with iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_ = {'rho': 1.e3, 'P': 1.e2, 'v': 42.}\n",
    "# Works also with 'values' and 'items'\n",
    "print dict_.keys()\n",
    "print dict_.iterkeys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concatenate vs. extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you concatenate, Python has to evaluate the list to access the last element. When you extend, Python creates each element without evaluating the list or accessing the last created element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initListConcat(n=100):\n",
    "    list_ = []\n",
    "    for i in xrange(n):\n",
    "        list_.append(i)\n",
    "    return list_\n",
    "\n",
    "def initListExtend(n=100):\n",
    "    list_ = [i for i in xrange(n)]\n",
    "    return list_\n",
    "\n",
    "%timeit initListConcat()\n",
    "%timeit initListExtend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NumPy tricks -- optimize your memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to array operations that are to favor over loops (there is almost always a way not to use loops), one should be careful with the memory usage with NumPy. NumPy tends to create a lot of temporary arrays that can cost a lot in memory. For example, if you want to simply perform a multiplication on an array (see above), NumPy will create a temporary array to stock the result, before asigning it to the original arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(10)\n",
    "# Therefore, if you want to multiply your array:\n",
    "a = 2*a\n",
    "# prefer one of the following expression:\n",
    "a *= 2\n",
    "np.multiply(a, 2, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: if you need a small view on an big array, you should probably prefer to copy the view, as an array can't be destroyed while a view exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigArr = np.arange(1000000)\n",
    "view = bigArr[42:45]\n",
    "view.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, take a look at the `OWNDATA` field: `view` does not own its data. So, if you want to delete `bigArr` (with `del bigArr`), you will delete your direct access to its memory, but you won't delete it in memory, since it is in used by `view`.\n",
    "\n",
    "On the contrary, if you use the `.copy()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view = bigArr[42:45].copy()\n",
    "view.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now see that `view` owns its data, and the big array can actually be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code testing** is a good practice as soon as you start developping anything. It is crucial for two main reasons:\n",
    "- ensure that what you coded behave as expected (through *unit tests* and *integration tests*);\n",
    "- ensure that you don't break what you previously did when you are in the development process (*regression tests*). Of course, it has to be combined with **versioning** if you want it to be efficient. Versioning is out of the scope of this workshop, but if you don't use it, please do (and I warmly recommand you to use **Git**).\n",
    "\n",
    "Here, I will focus solely on *unit testing*, meaning that we will test only the smallest testable unit of the program. In most cases, it means that we will test independently Python functions. *Unit testing* is sometimes referred as *whitebox testing*, because you have to know the content of your source code to test it properly. It can be opposed to *blackbox testing* (as *integration tests*) where you will test the wole code with a test case, not knowing what is inside the code, but knowing what it should return on this peculiar case.\n",
    "\n",
    "You could always test things directly on your code with `assert`ions, but it is both unefficient and it would be a pain to actually run all the tests you would have written. To make the task easier, different modules and frameworks exist for testing; I will here only talk about `unittest`, which comes from the standard library, and `pytest`, that is slightly more user-friendly (and included in your Anaconda distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `unittest` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic behind `unittest` is to create a class for each group of tests you want to perform, with some restrictions: the name of the class has to start by *`Test`* and it has to inherit from `unittest.TestCase`. Then, every method in the class starting by `test_` is a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file cyutils.pyx\n",
    "import cython\n",
    "import numpy as np\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cdef double f(double x):\n",
    "    return 4./(1. + x*x)\n",
    "\n",
    "def compPi_cython(int niter=1000):\n",
    "    cdef:\n",
    "        int i\n",
    "        double error\n",
    "        double h  = 1./niter\n",
    "        double pi = 0.\n",
    "    for i in xrange(niter):\n",
    "        x   = h*(i - 0.5)\n",
    "        pi += f(x)\n",
    "    error = abs(np.arccos(-1.) - pi*h)/np.arccos(-1.)\n",
    "    return pi*h, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "export FCC=gcc\n",
    "export IPYPATH=$(which ipython)\n",
    "export CONDAPATH=${IPYPATH%/*/*}\n",
    "export PYINC=$CONDAPATH/include/python2.7\n",
    "cython cyutils.pyx\n",
    "$FCC -fPIC -shared -O3 -Wall -fno-strict-aliasing -I$PYINC -o cyutils.so cyutils.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file test.py\n",
    "import unittest\n",
    "import cyutils\n",
    "import math\n",
    "\n",
    "class TestPi(unittest.TestCase):\n",
    "    def test_result(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        pi, error = cyutils.compPi_cython(niter)\n",
    "        self.assertLess(abs(math.pi - pi)/math.pi, prec)\n",
    "    \n",
    "    def test_prec_result(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        pi, error = cyutils.compPi_cython(niter)\n",
    "        self.assertLess(error, prec)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means the tests successfuly passed. You can notice the dots at the beginning of the output: each dot is a successful test.\n",
    "\n",
    "What happens if it fails? There are two different cases:\n",
    "- a logical error: something is actually wrong in the test;\n",
    "- a failure: the test actually fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file test.py\n",
    "import unittest\n",
    "import cyutils\n",
    "import math\n",
    "\n",
    "class TestPi(unittest.TestCase):\n",
    "    def test_result(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        pi, error = cyutils.compPi_cython(niter)\n",
    "        self.assertLess(abs(math.pi - pi)/math.pi, prec)\n",
    "    \n",
    "    def test_prec_result(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        pi, error = cyutils.compPi_cython(niter)\n",
    "        self.assertLess(error, prec)\n",
    "        \n",
    "    def test_result_logical_error(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        # Add a logical error (complex can't be converted to int)\n",
    "        pi, error = cyutils.compPi_cython(1j)\n",
    "        self.assertLess(abs(math.pi - pi)/math.pi, prec)\n",
    "    \n",
    "    def test_prec_result_failure(self, niter=1000):\n",
    "        prec = 1./niter\n",
    "        pi, error = cyutils.compPi_cython(niter)\n",
    "        # Add a failure (this test should not pass)\n",
    "        self.assertGreater(error, prec)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing you should notice is that two tests succeeded (two dots at the beginning) and there is a `F` (like failure) and an `E` (like error). Then, it returns us informations about the errors: it says if it is an error (logical error, something wrong within the test) or a failure (the test did not pass). Then, the faulting test is explicitely given, and a traceback explains the reason why it failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though `unittest` comes along in the standard library, it is a quite heavy machinery to use, it is very verbose. To test your code is great, to test it efficiently is even better. Thankfully, other libraries exist, like `pytest`. `pytest` is an efficient unit framework, simpler to use, more natural to use, and with less *boilerplate code*.\n",
    "\n",
    "The tests written previously then become:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file test_pi.py\n",
    "import math\n",
    "import cyutils\n",
    "\n",
    "def test_result(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(niter)\n",
    "    assert abs(math.pi - pi)/math.pi < prec\n",
    "    \n",
    "def test_prec_result(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(niter)\n",
    "    assert error < prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!py.test ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some magic has to happen to make it works:\n",
    "- the file containing the tests should be named `test_*.py`;\n",
    "- the test functions should also be named `test_()`;\n",
    "- `assert`ions need to be made; these are automatically detected by `pytest` which analysed them, and deduce the proper tests to run.\n",
    "\n",
    "And for the failing tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file test_pi.py\n",
    "import math\n",
    "import cyutils\n",
    "\n",
    "def test_result(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(niter)\n",
    "    assert abs(math.pi - pi)/math.pi < prec\n",
    "    \n",
    "def test_prec_result(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(niter)\n",
    "    assert error < prec\n",
    "    \n",
    "def test_result_logical_error(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(1j)\n",
    "    assert abs(math.pi - pi)/math.pi < prec\n",
    "    \n",
    "def test_prec_result_failure(niter=1000):\n",
    "    prec = 1./niter\n",
    "    pi, error = cyutils.compPi_cython(niter)\n",
    "    assert error > prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!py.test ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not distinguish between logical errors and test failure, but the output is highly readable and should help you anyway to get what went wrong with your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to go further..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Profiling:**\n",
    "- [Profiling in the Python documentation](https://docs.python.org/2/library/profile.html)\n",
    "- [Python module of the Week](http://pymotw.com/2/profile/)\n",
    "\n",
    "**Cython:**\n",
    "- [Cython userguide](http://docs.cython.org/src/userguide/): lots of general informations\n",
    "- [Cython docs: typed memoryviews](http://docs.cython.org/src/userguide/memoryviews.html): useful for working with numpy arrays\n",
    "- [Cython and NumPy](http://docs.cython.org/src/tutorial/numpy.html): some of this is currently a bit out-dated, but that should be addressed in the coming months.\n",
    "- [Scipy Conference 2013 Cython tutorial](http://conference.scipy.org/scipy2013/tutorial_detail.php?id=105) Very good video tutorial by one of Cython's main contributors.\n",
    "\n",
    "**ctypes:**\n",
    "- [CTypes Documentation](http://docs.python.org/2/library/ctypes.html)\n",
    "- [CTypes Tutorial](http://python.net/crew/theller/ctypes/tutorial.html)\n",
    "- [Scipy Cookbook: Ctypes](http://wiki.scipy.org/Cookbook/Ctypes)\n",
    "- [Sage Ctypes Documentation](http://www.sagemath.org/doc/numerical_sage/ctypes.html)\n",
    "\n",
    "**f2py:**\n",
    "- [F2Py user's guide](http://cens.ioc.ee/projects/f2py2e/usersguide/)\n",
    "- [SciPy F2Py cookbook](http://wiki.scipy.org/Cookbook/F2Py)\n",
    "- [numpy docs: using Python as glue](docs.scipy.org/doc/numpy/user/c-info.python-as-glue.htmlâ€Ž)\n",
    "- [Sage F2Py documentation](http://www.sagemath.org/doc/numerical_sage/f2py.html)\n",
    "\n",
    "**Numba:**\n",
    "- [Numba documentation](http://numba.pydata.org/doc.html)\n",
    "- [Accelerating Python with Numba](http://continuum.io/blog/numba_performance)\n",
    "- [Numba vs. Cython](http://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/)\n",
    "\n",
    "**multiprocessing:**\n",
    "- [Python documentation](https://docs.python.org/2/library/multiprocessing.html)\n",
    "- [Python Module of the Week](http://pymotw.com/2/multiprocessing/basics.html)\n",
    "\n",
    "**mpi4py:**\n",
    "- [pyHPC tutorial](http://nbviewer.ipython.org/github/pyhpc/pyhpc-tutorial/blob/master/notebooks/03_Scaling_Python.ipynb)\n",
    "\n",
    "**unit tests:**\n",
    "- [Python documentation](https://docs.python.org/2/library/unittest.html)\n",
    "- [pytest documentation](http://pytest.org/latest/)\n",
    "- [unit tests in *Dive into Python*](http://www.diveintopython.net/unit_testing/index.html#roman.intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
